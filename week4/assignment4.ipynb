{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, ZeroPadding2D\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: &quot;sequential_22&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_63 (Conv2D)           (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_40 (MaxPooling (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_64 (Conv2D)           (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_41 (MaxPooling (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_65 (Conv2D)           (None, 3, 3, 64)          36928     \n=================================================================\nTotal params: 55,744\nTrainable params: 55,744\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# PROBLEM 1\n",
    "# Model from the assignment\n",
    "model = models.Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# Show the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the summary above, we see three columns: the Layer (type), the Output Shape, and the Param #. In order to calculate the final column, we will also need the number of filters and the kernel size, which we will pull directly from the code for the model above. Generally speaking, in neural network architecture the formula for learnable params is: (inputs * ouputs) + biases. For CNNs, the inputs are the number of filters of the previous layer (if prev layer is dense, it is the number of nodes), the outputs are the number of filters in the current layer * size of those filters, and the bias is the number of filters in the current layer.\n",
    "\n",
    "# So, in the model summary above, the Param # for each layer is as follows:\n",
    "# 1. (32 * 9) + 32 = 320\n",
    "# 2. 0 because max pooling is functional and has no learnable params\n",
    "# 3. (32 * 64 * 9) + 64 = 18496\n",
    "# 4. 0 because max pooling is functional and has no learnable params\n",
    "# 5. (64 * 64 * 9) + 64 = 36928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data from mnist using code from assignment\n",
    "# Split into train images/labels and test images/labels\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshape train/test images to include an explicit channel\n",
    "# Convert train/test images to float32 type for use in CNN\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Convert to categorical using keras utility function\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n938/938 [==============================] - 19s 20ms/step - loss: 0.1789 - accuracy: 0.9443\nEpoch 2/5\n938/938 [==============================] - 18s 20ms/step - loss: 0.0470 - accuracy: 0.9857\nEpoch 3/5\n938/938 [==============================] - 19s 20ms/step - loss: 0.0326 - accuracy: 0.9899\nEpoch 4/5\n938/938 [==============================] - 19s 20ms/step - loss: 0.0247 - accuracy: 0.9924\nEpoch 5/5\n938/938 [==============================] - 18s 20ms/step - loss: 0.0190 - accuracy: 0.9942\n"
    }
   ],
   "source": [
    "# PROBLEM 2\n",
    "# Define model with maxpooling layers, based on code from assignment\n",
    "# Add maxpooling layer after each conv2d layers\n",
    "\n",
    "# Define number of epochs for use throughout the assignment\n",
    "num_epochs = 5\n",
    "\n",
    "max_model = models.Sequential([\n",
    "    Conv2D( 32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compile and fit model according to assignment instructions, retaining history for later recall\n",
    "max_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "max_history = max_model.fit(train_images, train_labels, epochs=num_epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n938/938 [==============================] - 18s 19ms/step - loss: 0.2146 - accuracy: 0.9327\nEpoch 2/5\n938/938 [==============================] - 18s 19ms/step - loss: 0.0587 - accuracy: 0.9816\nEpoch 3/5\n938/938 [==============================] - 18s 19ms/step - loss: 0.0392 - accuracy: 0.9877\nEpoch 4/5\n938/938 [==============================] - 18s 19ms/step - loss: 0.0309 - accuracy: 0.9908\nEpoch 5/5\n938/938 [==============================] - 18s 19ms/step - loss: 0.0244 - accuracy: 0.9927\n"
    }
   ],
   "source": [
    "# Define model with average pooling, based on code from assignment\n",
    "# Add avgpooling layer after each conv2d layers\n",
    "avg_model = models.Sequential([\n",
    "    Conv2D( 32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    AveragePooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    AveragePooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compile and fit model according to assignment instructions, retaining history for later recall\n",
    "avg_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "avg_history = avg_model.fit(train_images, train_labels, epochs=num_epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;plt&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-73-35558cce2b58&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plot max and average accuracy against number of epochs using matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m&#39;Max&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m&#39;Avg&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Add title, labels, and legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;plt&#39; is not defined"
     ]
    }
   ],
   "source": [
    "# Get accuracy from max and avg models from their respective history data\n",
    "max_accuracy = max_history.history['accuracy']\n",
    "avg_accuracy = avg_history.history['accuracy']\n",
    "# Define range of epochs for use in \n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Plot max and average accuracy against number of epochs using matplotlib\n",
    "plt.plot(epochs, max_accuracy, label='Max')\n",
    "plt.plot(epochs, avg_accuracy, label='Avg')\n",
    "# Add title, labels, and legend\n",
    "plt.title('Accuracy for Max and Average Pooling')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot above shows that the maxpooling model achieves a higher overall accuracy and has a higher increase at each epoch number\n",
    "# This is understandable. In book: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROBLEM 3\n",
    "# Define results dict for storing accuracy values\n",
    "results_max = {}\n",
    "# Define all filer sizes for use in loop\n",
    "filter_sizes = [ \n",
    "    ('3x3',(3,3)),\n",
    "    ('4x4',(4,4)),\n",
    "    ('5x5',(5,5)),\n",
    "    ('6x6',(6,6))\n",
    "]\n",
    "# Increase number of epochs to make plot slightly more clear\n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Loop through all filtersizes and train a model with maxpooling layers\n",
    "for filter_name, filter_size in filter_sizes:\n",
    "    model = models.Sequential([\n",
    "        Conv2D( 32, filter_size, activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    # Compile and fit model according to assignment instructions, retaining history for later recall\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_images, train_labels, epochs=num_epochs, batch_size=64)\n",
    "    # Get accuracy from history and add to results dict\n",
    "    accuracy = history.history['accuracy']\n",
    "    results_max[filter_name] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous plot\n",
    "plt.clf()\n",
    "# Increase size of plot for clarity\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "# Each key-value pair in the results dict is the name of the kernel size and a list of accuracy values at each epoch, respectively.\n",
    "for key, val in results_max.items():\n",
    "    # Plot accuracy against number of epochs\n",
    "    plt.plot(epochs, val, label=key)\n",
    "# Add title, labels, and legend\n",
    "plt.title('Accuracy for Kernel Sizes')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot shows that the model with the 3x3 kernel trains a bit slower, but ultimately has the highest accuracy\n",
    "# The model with the 5x5 kernel learns the fastest but is the second worst.\n",
    "# The model with the 4x4 kernel appears to be converging with the 3x3 at epoch 7, which is not shown here, as I'm keeping the number of epochs consistent for use later. But I did this calculation previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROBLEM 4\n",
    "# Define results dict for storing accuracy values\n",
    "results_padding = {}\n",
    "# Define model with zero padding layer before each conv2d layer\n",
    "padding_model = models.Sequential([\n",
    "    ZeroPadding2D(padding=(3,3)),\n",
    "    Conv2D( 32, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    ZeroPadding2D(padding=(3,3)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    ZeroPadding2D(padding=(3,3)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compile and fit model according to assignment instructions, retaining history for later recall\n",
    "padding_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "padding_model_history = padding_model.fit(train_images, train_labels, epochs=num_epochs, batch_size=64)\n",
    "# Get accuracy and add to results dict\n",
    "accuracy = padding_model_history.history['accuracy']\n",
    "results_padding['padding'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model without padding layers added\n",
    "no_padding_model = models.Sequential([\n",
    "    Conv2D( 32, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compile and fit model according to assignment instructions, retaining history for later recall\n",
    "no_padding_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "no_padding_model_history = no_padding_model.fit(train_images, train_labels, epochs=num_epochs, batch_size=64)\n",
    "# Get accuracy and add to results dict\n",
    "accuracy = no_padding_model_history.history['accuracy']\n",
    "results_padding['no_padding'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add accuracy of max model in problem 2\n",
    "results_padding['original'] = max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear plot\n",
    "plt.clf()\n",
    "epochs = range(1, num_epochs + 1)\n",
    "print(epochs)\n",
    "# Increase size of plot for clarity\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "# Loop through padding results dict\n",
    "# Each item is the key (name) and value (list of accuracy values)\n",
    "for key, val in results_padding.items():\n",
    "    # Plot accuracy against number of epochs\n",
    "    plt.plot(epochs, val, label=key)\n",
    "# Add title, labels, and legend\n",
    "plt.title('Accuracy for Padding Models')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot shows that the model with padding achieves higher accuracy overall and with less training. The second best is the original and not padding is the worst in the end, though that one trains a little faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROBLEM 5\n",
    "# Define url for cat picture\n",
    "url = 'https://cdn.cnn.com/cnnnext/dam/assets/200713171600-02-silk-road-cats-exlarge-169.jpg'\n",
    "# Get image at url using request module and open using PIL\n",
    "img = Image.open(request.urlopen(url))\n",
    "# Define size, kernel, scale, and offset of image\n",
    "size = (3,3)\n",
    "kernel = (-1, -1, -1, -1, 8, -1, -1, -1, -1)\n",
    "scale = 1\n",
    "offset = 0\n",
    "# Define laplace filter, using PIL ImageFilter\n",
    "laplace_filter = ImageFilter.Kernel( size=size, kernel=kernel, scale=scale, offset=offset)\n",
    "# Make img with edges detected using laplace filter\n",
    "img_edge = img.filter(laplace_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear plot\n",
    "plt.clf()\n",
    "# Use subplots to get plots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\n",
    "# Show first image\n",
    "ax1.imshow(img)\n",
    "# Remove ticks and set title\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Show second image\n",
    "ax2.imshow(img_edge)\n",
    "# Remove ticks and set title\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('After Processing with Edge Detection Filter')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}